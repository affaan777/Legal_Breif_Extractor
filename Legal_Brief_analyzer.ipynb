{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install PyPDF2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V2V8URLqkqxq",
        "outputId": "0ed0278f-8808-4a23-f074-5c81b5362444"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyPDF2\n",
            "Successfully installed PyPDF2-3.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QdnGpwKaQ6pA",
        "outputId": "04dcaf5a-2ff5-4368-8fc9-a1c6f087ff76"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Libraries imported successfully\n",
            "- PyPDF2: PDF text extraction\n",
            "- Pandas: Data organization\n",
            "- NLTK: Natural language processing\n",
            "Ready to dynamically extract key items\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "Legal Brief Key Items Extractor - Dynamic Extraction\n",
        "Automatically identifies key arguments using NLP techniques\n",
        "\"\"\"\n",
        "\n",
        "# Uncomment if libraries are not installed\n",
        "# !pip install PyPDF2 pandas openpyxl nltk\n",
        "\n",
        "import re\n",
        "import json\n",
        "import os\n",
        "from typing import List, Dict, Optional, Tuple\n",
        "import PyPDF2\n",
        "import pandas as pd\n",
        "from collections import Counter, defaultdict\n",
        "import nltk\n",
        "\n",
        "# Download required NLTK data\n",
        "try:\n",
        "    nltk.download('punkt_tab', quiet=True)\n",
        "    nltk.download('stopwords', quiet=True)\n",
        "except:\n",
        "    pass\n",
        "\n",
        "from nltk.tokenize import sent_tokenize\n",
        "from nltk.corpus import stopwords as nltk_stopwords\n",
        "\n",
        "print(\"Libraries imported successfully\")\n",
        "print(\"- PyPDF2: PDF text extraction\")\n",
        "print(\"- Pandas: Data organization\")\n",
        "print(\"- NLTK: Natural language processing\")\n",
        "print(\"Ready to dynamically extract key items\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 2: Load PDF Document\n",
        "\"\"\"\n",
        "Extract text from PDF file\n",
        "\"\"\"\n",
        "\n",
        "PDF_FILE_PATH = \"/content/Amicus Brief on Behalf of Mississippi, Alabama, Alaska, Arkansas etc....pdf\"\n",
        "\n",
        "def load_pdf_with_pypdf2(file_path: str) -> Tuple[str, pd.DataFrame]:\n",
        "    \"\"\"Extract text and create page-level DataFrame\"\"\"\n",
        "    try:\n",
        "        with open(file_path, 'rb') as file:\n",
        "            pdf_reader = PyPDF2.PdfReader(file)\n",
        "            total_pages = len(pdf_reader.pages)\n",
        "\n",
        "            print(f\"Loading PDF: {os.path.basename(file_path)}\")\n",
        "            print(f\"Total pages: {total_pages}\\n\")\n",
        "\n",
        "            full_text = \"\"\n",
        "            page_data = []\n",
        "\n",
        "            for page_num, page in enumerate(pdf_reader.pages, 1):\n",
        "                page_text = page.extract_text()\n",
        "                full_text += f\"\\n--- PAGE {page_num} ---\\n{page_text}\"\n",
        "\n",
        "                page_data.append({\n",
        "                    'page_number': page_num,\n",
        "                    'text_content': page_text,\n",
        "                    'word_count': len(page_text.split()),\n",
        "                    'char_count': len(page_text)\n",
        "                })\n",
        "\n",
        "            pages_df = pd.DataFrame(page_data)\n",
        "            print(f\"Successfully extracted {len(full_text):,} characters from {total_pages} pages\\n\")\n",
        "\n",
        "            return full_text, pages_df\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(f\"ERROR: File not found: {file_path}\")\n",
        "        return \"\", pd.DataFrame()\n",
        "    except Exception as e:\n",
        "        print(f\"ERROR: {str(e)}\")\n",
        "        return \"\", pd.DataFrame()\n",
        "\n",
        "document_text, pages_dataframe = load_pdf_with_pypdf2(PDF_FILE_PATH)\n",
        "\n",
        "if document_text:\n",
        "    print(f\"Document loaded: Alliance for Hippocratic Medicine v. FDA\")\n",
        "    print(f\"Pages DataFrame shape: {pages_dataframe.shape}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hAS4NW3cREr8",
        "outputId": "8ffbc2e4-eec5-4177-e5ca-336575875496"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading PDF: Amicus Brief on Behalf of Mississippi, Alabama, Alaska, Arkansas etc....pdf\n",
            "Total pages: 26\n",
            "\n",
            "Successfully extracted 44,315 characters from 26 pages\n",
            "\n",
            "Document loaded: Alliance for Hippocratic Medicine v. FDA\n",
            "Pages DataFrame shape: (26, 4)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5DNUEr_rxzXl",
        "outputId": "a31b2703-9010-4b9f-d528-448a23fa5922"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk) (8.2.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk) (1.5.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk) (4.67.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 3: Define Dynamic Extraction Class\n",
        "\"\"\"\n",
        "Automatically extracts key legal arguments using pattern matching and scoring\n",
        "\"\"\"\n",
        "\n",
        "class DynamicLegalExtractor:\n",
        "    \"\"\"Dynamically extracts key items from legal briefs\"\"\"\n",
        "\n",
        "    def __init__(self, text: str, pages_df: pd.DataFrame):\n",
        "        self.text = text\n",
        "        self.pages_df = pages_df\n",
        "        self.sentences = []\n",
        "        self.stop_words = set(nltk_stopwords.words('english'))\n",
        "\n",
        "    def extract_sentences(self) -> List[Dict]:\n",
        "        \"\"\"Extract all sentences with metadata\"\"\"\n",
        "        sentences_data = []\n",
        "\n",
        "        for idx, row in self.pages_df.iterrows():\n",
        "            page_num = row['page_number']\n",
        "            page_text = row['text_content']\n",
        "\n",
        "            # Skip header/footer pages\n",
        "            if len(page_text) < 100:\n",
        "                continue\n",
        "\n",
        "            # Tokenize into sentences\n",
        "            sentences = sent_tokenize(page_text)\n",
        "\n",
        "            for sent in sentences:\n",
        "                if len(sent) > 50:  # Filter very short sentences\n",
        "                    sentences_data.append({\n",
        "                        'text': sent.strip(),\n",
        "                        'page': page_num,\n",
        "                        'length': len(sent),\n",
        "                        'word_count': len(sent.split())\n",
        "                    })\n",
        "\n",
        "        self.sentences = sentences_data\n",
        "        return sentences_data\n",
        "\n",
        "    def score_sentence(self, sentence: str) -> Dict[str, float]:\n",
        "        \"\"\"Score a sentence based on legal importance indicators\"\"\"\n",
        "\n",
        "        scores = {\n",
        "            'legal_citation': 0,\n",
        "            'modal_strength': 0,\n",
        "            'argument_indicator': 0,\n",
        "            'subject_relevance': 0,\n",
        "            'procedural': 0\n",
        "        }\n",
        "\n",
        "        sentence_lower = sentence.lower()\n",
        "\n",
        "        # Legal citations (statutes, cases, regulations)\n",
        "        citation_patterns = [\n",
        "            r'\\d+\\s+U\\.S\\.C\\.\\s+§\\s*\\d+',  # Federal statutes\n",
        "            r'\\d+\\s+C\\.F\\.R\\.\\s+§\\s*\\d+',  # Federal regulations\n",
        "            r'\\d+\\s+S\\.\\s*Ct\\.\\s+\\d+',     # Supreme Court\n",
        "            r'\\d+\\s+F\\.\\s*\\d+th\\s+\\d+',    # Federal courts\n",
        "            r'v\\.\\s+[A-Z][\\w\\s]+,\\s+\\d+',  # Case names\n",
        "        ]\n",
        "        for pattern in citation_patterns:\n",
        "            if re.search(pattern, sentence):\n",
        "                scores['legal_citation'] += 2\n",
        "\n",
        "        # Strong modal verbs indicating legal arguments\n",
        "        strong_modals = ['violate', 'defy', 'contradict', 'require', 'mandate',\n",
        "                        'prohibit', 'unlawful', 'invalid', 'unconstitutional']\n",
        "        scores['modal_strength'] = sum(2 for word in strong_modals if word in sentence_lower)\n",
        "\n",
        "        # Argument indicators\n",
        "        argument_phrases = [\n",
        "            'the fda', 'states have', 'public interest', 'court held',\n",
        "            'congress', 'administration', 'plaintiffs', 'amici'\n",
        "        ]\n",
        "        scores['argument_indicator'] = sum(1.5 for phrase in argument_phrases if phrase in sentence_lower)\n",
        "\n",
        "        # Key subject matter\n",
        "        key_subjects = ['mifepristone', 'abortion', 'approval', 'rems',\n",
        "                       'subpart h', 'dobbs', 'preemption', 'enforcement']\n",
        "        scores['subject_relevance'] = sum(1 for subj in key_subjects if subj in sentence_lower)\n",
        "\n",
        "        # Procedural importance\n",
        "        procedural_terms = ['injunction', 'relief', 'preliminary', 'motion', 'brief']\n",
        "        scores['procedural'] = sum(0.5 for term in procedural_terms if term in sentence_lower)\n",
        "\n",
        "        return scores\n",
        "\n",
        "    def extract_key_items(self, top_n: int = 10) -> pd.DataFrame:\n",
        "        \"\"\"Dynamically extract top N key items\"\"\"\n",
        "\n",
        "        print(\"Extracting sentences from document...\")\n",
        "        sentences_data = self.extract_sentences()\n",
        "        print(f\"Found {len(sentences_data)} sentences\\n\")\n",
        "\n",
        "        print(\"Scoring sentences for legal importance...\")\n",
        "        scored_items = []\n",
        "\n",
        "        for sent_data in sentences_data:\n",
        "            scores = self.score_sentence(sent_data['text'])\n",
        "            total_score = sum(scores.values())\n",
        "\n",
        "            # Only include sentences with meaningful scores\n",
        "            if total_score >= 3:\n",
        "                scored_items.append({\n",
        "                    'text': sent_data['text'],\n",
        "                    'page': sent_data['page'],\n",
        "                    'total_score': total_score,\n",
        "                    'legal_citation': scores['legal_citation'],\n",
        "                    'modal_strength': scores['modal_strength'],\n",
        "                    'argument_indicator': scores['argument_indicator'],\n",
        "                    'subject_relevance': scores['subject_relevance'],\n",
        "                    'word_count': sent_data['word_count']\n",
        "                })\n",
        "\n",
        "        # Sort by total score\n",
        "        scored_items.sort(key=lambda x: x['total_score'], reverse=True)\n",
        "\n",
        "        # Take top N\n",
        "        top_items = scored_items[:top_n]\n",
        "\n",
        "        # Categorize automatically\n",
        "        for i, item in enumerate(top_items, 1):\n",
        "            item['rank'] = i\n",
        "            item['category'] = self._categorize_sentence(item['text'])\n",
        "            item['importance'] = self._determine_importance(item['total_score'])\n",
        "\n",
        "        print(f\"Extracted top {len(top_items)} key items\\n\")\n",
        "\n",
        "        return pd.DataFrame(top_items)\n",
        "\n",
        "    def _categorize_sentence(self, text: str) -> str:\n",
        "        \"\"\"Automatically categorize based on content\"\"\"\n",
        "        text_lower = text.lower()\n",
        "\n",
        "        if 'u.s.c.' in text_lower or 'c.f.r.' in text_lower:\n",
        "            return 'Legal Violation'\n",
        "        elif 'dobbs' in text_lower or 'state' in text_lower:\n",
        "            return 'Constitutional Authority'\n",
        "        elif 'fda' in text_lower and ('approve' in text_lower or 'action' in text_lower):\n",
        "            return 'FDA Actions'\n",
        "        elif 'public interest' in text_lower or 'harm' in text_lower:\n",
        "            return 'Public Interest'\n",
        "        elif 'enforce' in text_lower or 'resource' in text_lower:\n",
        "            return 'State Enforcement'\n",
        "        else:\n",
        "            return 'General Legal Argument'\n",
        "\n",
        "    def _determine_importance(self, score: float) -> str:\n",
        "        \"\"\"Determine importance based on score\"\"\"\n",
        "        if score >= 8:\n",
        "            return 'Critical'\n",
        "        elif score >= 5:\n",
        "            return 'High'\n",
        "        else:\n",
        "            return 'Medium'\n",
        "\n",
        "    def export_to_excel(self, df: pd.DataFrame, filename: str = 'dynamic_analysis.xlsx'):\n",
        "        \"\"\"Export results to Excel\"\"\"\n",
        "        with pd.ExcelWriter(filename, engine='openpyxl') as writer:\n",
        "            df.to_excel(writer, sheet_name='Key Items', index=False)\n",
        "\n",
        "            # Summary sheet\n",
        "            summary = pd.DataFrame({\n",
        "                'Metric': ['Total Items', 'Critical', 'High', 'Medium',\n",
        "                          'Avg Score', 'Max Score', 'Total Pages'],\n",
        "                'Value': [\n",
        "                    len(df),\n",
        "                    len(df[df['importance'] == 'Critical']),\n",
        "                    len(df[df['importance'] == 'High']),\n",
        "                    len(df[df['importance'] == 'Medium']),\n",
        "                    round(df['total_score'].mean(), 2),\n",
        "                    df['total_score'].max(),\n",
        "                    len(self.pages_df)\n",
        "                ]\n",
        "            })\n",
        "            summary.to_excel(writer, sheet_name='Summary', index=False)\n",
        "\n",
        "            # Category breakdown\n",
        "            category_counts = df['category'].value_counts().reset_index()\n",
        "            category_counts.columns = ['Category', 'Count']\n",
        "            category_counts.to_excel(writer, sheet_name='Categories', index=False)\n",
        "\n",
        "        print(f\"Exported to {filename}\")\n",
        "\n",
        "print(\"DynamicLegalExtractor class defined\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0KxuNChIRROe",
        "outputId": "fd3f1c60-74d7-4f18-9cfa-be201c73fdf8"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DynamicLegalExtractor class defined\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 4: Initialize Dynamic Extractor\n",
        "\"\"\"\n",
        "Create extractor instance\n",
        "\"\"\"\n",
        "\n",
        "if document_text:\n",
        "    extractor = DynamicLegalExtractor(document_text, pages_dataframe)\n",
        "    print(\"Dynamic extractor initialized\")\n",
        "    print(\"Ready to extract key items automatically\\n\")\n",
        "else:\n",
        "    extractor = None\n",
        "    print(\"Cannot initialize - no document loaded\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_wRbc3RtRgD9",
        "outputId": "53b49133-4bae-47b3-9e97-b4b51c9c2c7f"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dynamic extractor initialized\n",
            "Ready to extract key items automatically\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\"\"\"\n",
        "Run dynamic extraction algorithm\n",
        "\"\"\"\n",
        "\n",
        "if extractor:\n",
        "    print(\"=\"*85)\n",
        "    print(\"DYNAMIC EXTRACTION - TOP 10 KEY ITEMS\")\n",
        "    print(\"=\"*85 + \"\\n\")\n",
        "\n",
        "    key_items_df = extractor.extract_key_items(top_n=10)\n",
        "\n",
        "    # Display results\n",
        "    display_cols = ['rank', 'category', 'importance', 'page', 'total_score', 'text']\n",
        "    print(key_items_df[display_cols].to_string(index=False, max_colwidth=60))\n",
        "else:\n",
        "    key_items_df = pd.DataFrame()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RBZU9TXCRnUA",
        "outputId": "01d82af4-be06-4577-af78-f5c6ba7b3fc9"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=====================================================================================\n",
            "DYNAMIC EXTRACTION - TOP 10 KEY ITEMS\n",
            "=====================================================================================\n",
            "\n",
            "Extracting sentences from document...\n",
            "Found 253 sentences\n",
            "\n",
            "Scoring sentences for legal importance...\n",
            "Extracted top 10 key items\n",
            "\n",
            " rank                 category importance  page  total_score                                                         text\n",
            "    1              FDA Actions       High     2          6.0 i \\n  \\nTABLE OF CONTENTS  \\nPage  \\nTABLE OF AUTHORITIES...\n",
            "    2 Constitutional Authority       High    13          6.0 They defy \\nfederal law , flout  the public -interest det...\n",
            "    3              FDA Actions       High    14          6.0 Amici emphasize that the FDA’s actions defy  both the age...\n",
            "    4   General Legal Argument       High    14          6.0 “ There is generally \\nno public  interest  in the perpet...\n",
            "    5 Constitutional Authority       High     9          5.5 Last, the FDA ’s actions threaten to \\nundermine  the ami...\n",
            "    6   General Legal Argument       High    11          5.5 Because of the serious \\nsafety concerns involved, the FD...\n",
            "    7 Constitutional Authority       High    23          5.5 Such enforcement  will be  especially hard in these circu...\n",
            "    8              FDA Actions       High     2          5.0 The Public Interest And Equities Weigh Strongly Against T...\n",
            "    9 Constitutional Authority       High     3          5.0 ii \\n TABLE OF AUTHORITIES  \\nPage(s)  \\nCases  \\nDobbs v...\n",
            "   10 Constitutional Authority       High     9          5.0 Second, the FDA ’s actions defy  the public -interest \\nd...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 6: Detailed Score Analysis\n",
        "\"\"\"\n",
        "Show scoring breakdown for each item\n",
        "\"\"\"\n",
        "\n",
        "if not key_items_df.empty:\n",
        "    print(\"\\n\" + \"=\"*85)\n",
        "    print(\"SCORE BREAKDOWN ANALYSIS\")\n",
        "    print(\"=\"*85 + \"\\n\")\n",
        "\n",
        "    score_cols = ['rank', 'legal_citation', 'modal_strength',\n",
        "                  'argument_indicator', 'subject_relevance', 'total_score']\n",
        "\n",
        "    print(\"Scoring Components:\")\n",
        "    print(key_items_df[score_cols].to_string(index=False))\n",
        "\n",
        "    print(\"\\n\" + \"-\"*85 + \"\\n\")\n",
        "    print(\"Score Statistics:\")\n",
        "    print(key_items_df['total_score'].describe())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "97IwvFUoRq_e",
        "outputId": "8cfa2b3a-d5c7-4d95-9253-c7f95c9ea7c6"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=====================================================================================\n",
            "SCORE BREAKDOWN ANALYSIS\n",
            "=====================================================================================\n",
            "\n",
            "Scoring Components:\n",
            " rank  legal_citation  modal_strength  argument_indicator  subject_relevance  total_score\n",
            "    1               0               0                 4.5                  1          6.0\n",
            "    2               0               2                 3.0                  1          6.0\n",
            "    3               0               2                 3.0                  1          6.0\n",
            "    4               4               2                 0.0                  0          6.0\n",
            "    5               0               0                 4.5                  1          5.5\n",
            "    6               0               2                 1.5                  2          5.5\n",
            "    7               0               2                 1.5                  2          5.5\n",
            "    8               0               2                 3.0                  0          5.0\n",
            "    9               4               0                 0.0                  1          5.0\n",
            "   10               0               2                 3.0                  0          5.0\n",
            "\n",
            "-------------------------------------------------------------------------------------\n",
            "\n",
            "Score Statistics:\n",
            "count    10.000000\n",
            "mean      5.550000\n",
            "std       0.437798\n",
            "min       5.000000\n",
            "25%       5.125000\n",
            "50%       5.500000\n",
            "75%       6.000000\n",
            "max       6.000000\n",
            "Name: total_score, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 7: Category Distribution\n",
        "\"\"\"\n",
        "Analyze automatically assigned categories\n",
        "\"\"\"\n",
        "\n",
        "if not key_items_df.empty:\n",
        "    print(\"\\n\" + \"=\"*85)\n",
        "    print(\"CATEGORY DISTRIBUTION\")\n",
        "    print(\"=\"*85 + \"\\n\")\n",
        "\n",
        "    category_counts = key_items_df['category'].value_counts()\n",
        "    print(\"Items by Category:\")\n",
        "    print(category_counts)\n",
        "\n",
        "    print(\"\\n\" + \"-\"*85 + \"\\n\")\n",
        "\n",
        "    importance_counts = key_items_df['importance'].value_counts()\n",
        "    print(\"Items by Importance:\")\n",
        "    print(importance_counts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d-tiwQqxR7dz",
        "outputId": "aafcf4d9-d5e7-4d65-cff1-7e2739cab535"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=====================================================================================\n",
            "CATEGORY DISTRIBUTION\n",
            "=====================================================================================\n",
            "\n",
            "Items by Category:\n",
            "category\n",
            "Constitutional Authority    5\n",
            "FDA Actions                 3\n",
            "General Legal Argument      2\n",
            "Name: count, dtype: int64\n",
            "\n",
            "-------------------------------------------------------------------------------------\n",
            "\n",
            "Items by Importance:\n",
            "importance\n",
            "High    10\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 8: Page Distribution Analysis\n",
        "\"\"\"\n",
        "Show which pages contain key arguments\n",
        "\"\"\"\n",
        "\n",
        "if not key_items_df.empty:\n",
        "    print(\"\\n\" + \"=\"*85)\n",
        "    print(\"PAGE DISTRIBUTION\")\n",
        "    print(\"=\"*85 + \"\\n\")\n",
        "\n",
        "    page_dist = key_items_df['page'].value_counts().sort_index()\n",
        "    print(\"Key Items per Page:\")\n",
        "    print(page_dist)\n",
        "\n",
        "    print(f\"\\nPage range: {key_items_df['page'].min()} - {key_items_df['page'].max()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LbuirrBgR_bx",
        "outputId": "7f2c2c53-84ce-4580-fbfa-123e8d2286a5"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=====================================================================================\n",
            "PAGE DISTRIBUTION\n",
            "=====================================================================================\n",
            "\n",
            "Key Items per Page:\n",
            "page\n",
            "2     2\n",
            "3     1\n",
            "9     2\n",
            "11    1\n",
            "13    1\n",
            "14    2\n",
            "23    1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Page range: 2 - 23\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 9: Export Results\n",
        "\"\"\"\n",
        "Save dynamically extracted data\n",
        "\"\"\"\n",
        "\n",
        "if extractor and not key_items_df.empty:\n",
        "    print(\"\\n\" + \"=\"*85)\n",
        "    print(\"EXPORTING RESULTS\")\n",
        "    print(\"=\"*85 + \"\\n\")\n",
        "\n",
        "    extractor.export_to_excel(key_items_df, 'dynamic_legal_analysis.xlsx')\n",
        "\n",
        "    # Also export to CSV\n",
        "    key_items_df.to_csv('key_items_dynamic.csv', index=False)\n",
        "    print(\"Also exported to: key_items_dynamic.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fVmgVYG-SIwl",
        "outputId": "cb9dbe4e-e852-4c5d-ec58-0f2546347f60"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=====================================================================================\n",
            "EXPORTING RESULTS\n",
            "=====================================================================================\n",
            "\n",
            "Exported to dynamic_legal_analysis.xlsx\n",
            "Also exported to: key_items_dynamic.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Final summary with extraction methodology\n",
        "\"\"\"\n",
        "\n",
        "if not key_items_df.empty:\n",
        "    print(\"\\n\" + \"=\"*85)\n",
        "    print(\"EXTRACTION SUMMARY\")\n",
        "    print(\"=\"*85 + \"\\n\")\n",
        "\n",
        "    print(\"METHODOLOGY:\")\n",
        "    print(\"  Dynamic NLP-based extraction using:\")\n",
        "    print(\"  • Legal citation pattern matching\")\n",
        "    print(\"  • Modal verb strength analysis\")\n",
        "    print(\"  • Argument indicator detection\")\n",
        "    print(\"  • Subject relevance scoring\")\n",
        "    print(\"  • Automatic categorization\\n\")\n",
        "\n",
        "    print(\"RESULTS:\")\n",
        "    print(f\"  Total sentences analyzed: {len(extractor.sentences)}\")\n",
        "    print(f\"  Key items extracted: {len(key_items_df)}\")\n",
        "    print(f\"  Critical items: {len(key_items_df[key_items_df['importance'] == 'Critical'])}\")\n",
        "    print(f\"  High priority items: {len(key_items_df[key_items_df['importance'] == 'High'])}\")\n",
        "    print(f\"  Average relevance score: {key_items_df['total_score'].mean():.2f}\")\n",
        "\n",
        "    print(\"\\n\" + \"=\"*85)\n",
        "    print(\"=\"*85)\n",
        "    print(\"\\nAll items extracted dynamically from PDF content\")\n",
        "    print(\"Scoring algorithm can be adjusted based on legal domain needs\")\n",
        "else:\n",
        "    print(\"No analysis available\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vGoucgT71U9y",
        "outputId": "90a8e818-a3f6-41de-9bdf-ee14b80a293f"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=====================================================================================\n",
            "EXTRACTION SUMMARY\n",
            "=====================================================================================\n",
            "\n",
            "METHODOLOGY:\n",
            "  Dynamic NLP-based extraction using:\n",
            "  • Legal citation pattern matching\n",
            "  • Modal verb strength analysis\n",
            "  • Argument indicator detection\n",
            "  • Subject relevance scoring\n",
            "  • Automatic categorization\n",
            "\n",
            "RESULTS:\n",
            "  Total sentences analyzed: 253\n",
            "  Key items extracted: 10\n",
            "  Critical items: 0\n",
            "  High priority items: 10\n",
            "  Average relevance score: 5.55\n",
            "\n",
            "=====================================================================================\n",
            "=====================================================================================\n",
            "\n",
            "All items extracted dynamically from PDF content\n",
            "Scoring algorithm can be adjusted based on legal domain needs\n"
          ]
        }
      ]
    }
  ]
}